{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "RgxUVqXzwnWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e3c0e9d-a1fb-409a-8a3b-94c7c63b8e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J9hg8gFPuyq",
        "outputId": "8b278e22-e7c1-4586-eb78-d2ed52e39100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "path = '/content/drive/MyDrive/ML_final/'\n",
        "print(glob.glob(path+'data/*')[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B241T-eUSXPr",
        "outputId": "f4216398-b22c-4b30-8f89-177842c7de5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/ML_final/data/cat_1284.png', '/content/drive/MyDrive/ML_final/data/cat_1285.png', '/content/drive/MyDrive/ML_final/data/cat_1287.png', '/content/drive/MyDrive/ML_final/data/cat_1286.png', '/content/drive/MyDrive/ML_final/data/cat_1290.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer, ViTFeatureExtractor, ViTForImageClassification, TrainerCallback\n",
        "import torch\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datasets\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "_Ixm-L3YSdyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname = 'dataset.csv'\n",
        "label_map = {'neg': 0, 'neu': 1, 'pos': 2}\n",
        "\n",
        "def preprocess(fname):\n",
        "    df = pd.read_csv(path + fname)\n",
        "    df['image'] = df['image'].apply(lambda x: path + 'data/' + x)\n",
        "    df['label'] = df['label'].map(label_map)\n",
        "    df['label'] = df['label'].astype(int)\n",
        "    return df\n",
        "\n",
        "def gen(df):\n",
        "  for i, row in df.iterrows():\n",
        "    yield {'image': Image.open(row['image']).convert('RGB'), 'labels': row['label']}\n",
        "\n",
        "df = preprocess(fname)\n",
        "dataset = Dataset.from_generator(lambda: gen(df))"
      ],
      "metadata": {
        "id": "wHrepay7wWPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teEnoRypGJ11",
        "outputId": "076faf84-0b0b-4799-8977-bb2f73230303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['image', 'labels'],\n",
            "    num_rows: 500\n",
            "})\n",
            "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1446x1660 at 0x7BEB27689410>, 'labels': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "def transform(example_batch):\n",
        "    # Take a list of PIL images and turn them to pixel values\n",
        "    inputs = feature_extractor([x for x in example_batch['image']], return_tensors='pt')\n",
        "\n",
        "    # Don't forget to include the labels!\n",
        "    inputs['labels'] = example_batch['labels']\n",
        "    return inputs\n",
        "\n",
        "def shuffle_split(dataset):\n",
        "    dataset = dataset.with_transform(transform).train_test_split(test_size=0.2, seed=23)\n",
        "    return dataset['train'], dataset['test']\n",
        "\n",
        "def load_model():\n",
        "    \"\"\" Load a text model for classifiying num_labels \"\"\"\n",
        "    model = ViTForImageClassification.from_pretrained(\n",
        "        'google/vit-base-patch16-224-in21k',\n",
        "        num_labels=3,\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return {\n",
        "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
        "        'labels': torch.tensor([x['labels'] for x in batch])\n",
        "    }\n",
        "\n",
        "\n",
        "class EpochReportCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.epoch_losses = []\n",
        "        self.current_epoch_losses = []\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is not None and \"loss\" in logs:\n",
        "            self.current_epoch_losses.append(logs[\"loss\"])\n",
        "\n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "        if self.current_epoch_losses:\n",
        "            avg_loss = np.mean(self.current_epoch_losses)\n",
        "            self.epoch_losses.append(avg_loss)\n",
        "            print(f\"Epoch {state.epoch}: Average loss = {avg_loss:.4f}\")\n",
        "            self.current_epoch_losses = []\n",
        "\n",
        "def train_model(model, train_data):\n",
        "    \"\"\" Train text model for classification \"\"\"\n",
        "    feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "    training_args = TrainingArguments(\n",
        "          output_dir=\"./vit-base-cat-demo\",\n",
        "          per_device_train_batch_size=32,\n",
        "          report_to=\"none\",\n",
        "          num_train_epochs=7,\n",
        "          save_steps=100,\n",
        "          logging_steps=100,\n",
        "          logging_strategy=\"epoch\",\n",
        "          learning_rate=2e-4,\n",
        "          save_total_limit=2,\n",
        "          remove_unused_columns=False,\n",
        "          push_to_hub=False,\n",
        "        )\n",
        "\n",
        "    epoch_reporter = EpochReportCallback()\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=collate_fn,\n",
        "        train_dataset=train_data,\n",
        "        tokenizer=feature_extractor,\n",
        "        callbacks=[epoch_reporter],\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    return epoch_reporter.epoch_losses\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_predictions(m, data):\n",
        "    m.eval()\n",
        "    m.to('cpu')\n",
        "\n",
        "    predictions = []\n",
        "    data = collate_fn(data)\n",
        "    batchSize = 20\n",
        "    for batch_idx in range(0, len(data['pixel_values']), batchSize):\n",
        "        input = data['pixel_values'][batch_idx:batch_idx+batchSize]\n",
        "        predictions += list(torch.argmax(m(input).logits, dim=-1).numpy())\n",
        "\n",
        "    return torch.tensor(predictions), data['labels']\n"
      ],
      "metadata": {
        "id": "IE2uU0vbhFQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd575305-6853-4038-8b51-45bfe758bb2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "train_data, test_data = shuffle_split(dataset)\n",
        "model = load_model()\n",
        "\n",
        "preds, labels = get_predictions(model, test_data)\n",
        "accuracy = (preds == labels).float().mean().item()\n",
        "print(f'initial accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "#print(preds, labels)\n",
        "y_pred = preds.tolist()\n",
        "y_true = labels.tolist()\n",
        "\n",
        "label_names = ['neg', 'neu', 'pos']\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST-J7jexJFQM",
        "outputId": "e6007c30-e8f2-408c-b910-db6c4a066504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial accuracy: 40.00%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.45      0.39      0.42        36\n",
            "         neu       0.40      0.64      0.50        39\n",
            "         pos       0.14      0.04      0.06        25\n",
            "\n",
            "    accuracy                           0.40       100\n",
            "   macro avg       0.33      0.36      0.33       100\n",
            "weighted avg       0.36      0.40      0.36       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = train_data[0]\n",
        "print(example['pixel_values'].shape)\n",
        "print(example['labels'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5okuZ6SORPP",
        "outputId": "1a08a26c-6ca8-4463-e5b0-f227043cd96c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_data)\n",
        "\n",
        "preds, labels = get_predictions(model, test_data)\n",
        "accuracy = (preds == labels).float().mean().item()\n",
        "print(f'final accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "#print(preds, labels)\n",
        "y_pred = preds.tolist()\n",
        "y_true = labels.tolist()\n",
        "\n",
        "label_names = ['neg', 'neu', 'pos']\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "id": "YpFHJkD3UdKV",
        "outputId": "985c97fa-d47a-45bf-8598-9d878cd9a364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n",
            "<ipython-input-7-d59d9e79b46f>:65: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='91' max='91' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [91/91 1:37:05, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.088800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.901100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.595500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.258400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.112900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.063500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.051400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2.0: Average loss = 1.0888\n",
            "Epoch 3.0: Average loss = 0.9011\n",
            "Epoch 4.0: Average loss = 0.5955\n",
            "Epoch 5.0: Average loss = 0.2584\n",
            "Epoch 6.0: Average loss = 0.1129\n",
            "Epoch 7.0: Average loss = 0.0635\n",
            "final accuracy: 55.00%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.57      0.67      0.62        36\n",
            "         neu       0.55      0.62      0.58        39\n",
            "         pos       0.50      0.28      0.36        25\n",
            "\n",
            "    accuracy                           0.55       100\n",
            "   macro avg       0.54      0.52      0.52       100\n",
            "weighted avg       0.54      0.55      0.54       100\n",
            "\n"
          ]
        }
      ]
    }
  ]
}